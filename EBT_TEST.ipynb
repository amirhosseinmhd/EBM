{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T01:06:23.893558Z",
     "start_time": "2025-10-02T01:06:23.885362Z"
    }
   },
   "source": [
    "import torch\n",
    "from model import EBTS1Model, get_model_config, init_whole_model_weights\n",
    "\n",
    "# 1. Get configuration for xxs model\n",
    "config = get_model_config('xxs')\n",
    "print(f\"Model: {config.n_layers} layers, {config.dim} dim, {config.n_heads} heads\")\n"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'EBTS1Model' from 'model' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmodel\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m EBTS1Model, get_model_config, init_whole_model_weights\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# 1. Get configuration for xxs model\u001B[39;00m\n\u001B[1;32m      5\u001B[0m config \u001B[38;5;241m=\u001B[39m get_model_config(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mxxs\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'EBTS1Model' from 'model' (unknown location)"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T01:06:24.104689Z",
     "start_time": "2025-10-02T01:06:24.096772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 2. Create model\n",
    "vocab_size = 50277  # GPT-NeoX tokenizer\n",
    "model = EBTS1Model(config, vocab_size=vocab_size, pad_token_id=0)\n"
   ],
   "id": "103923f29b097bcc",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EBTS1Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 2. Create model\u001B[39;00m\n\u001B[1;32m      2\u001B[0m vocab_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m50277\u001B[39m  \u001B[38;5;66;03m# GPT-NeoX tokenizer\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mEBTS1Model\u001B[49m(config, vocab_size\u001B[38;5;241m=\u001B[39mvocab_size, pad_token_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'EBTS1Model' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# 3. Initialize weights\n",
    "init_whole_model_weights(model, \"xavier\")\n",
    "\n",
    "# 4. Check model size\n",
    "print(f\"Parameters: {model.get_num_params():,}\")\n",
    "\n",
    "# 5. Training forward pass\n",
    "input_ids = torch.randint(0, vocab_size, (4, 256))  # (batch=4, seq_len=256)\n",
    "\n",
    "# Forward pass (2 optimization steps by default)\n",
    "pred_dists, energies, embeds = model(input_ids, mcmc_num_steps=2, learning=True)\n",
    "\n",
    "# Compute loss\n",
    "loss, metrics = model.compute_loss(input_ids, pred_dists)\n",
    "print(f\"Loss: {metrics['loss']:.4f}, Perplexity: {metrics['perplexity']:.2f}\")\n",
    "print(f\"Step size Î±: {metrics['alpha']:.1f}\")\n",
    "\n",
    "# Backpropagation\n",
    "loss.backward()\n",
    "\n",
    "# 6. Generation\n",
    "generated = model.generate(\n",
    "    input_ids[:, :10],  # Prompt\n",
    "    max_new_tokens=50,\n",
    "    temperature=0.8,\n",
    "    mcmc_num_steps=2\n",
    ")"
   ],
   "id": "56900e7de99c5283"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
